{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69b24f17-2d3c-4164-b6b5-78bb0127d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import Sequential\n",
    "import keras.layers as layers\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a9e609",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f24f07a7-d530-4813-a59b-055fc054f2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Maltese_dog', 'Afghan_hound', 'Scottish_deerhound', 'Pomeranian', 'Irish_wolfhound', 'Bernese_mountain_dog', 'Samoyed', 'Shih-Tzu', 'Great_Pyrenees', 'Leonberg']\n"
     ]
    }
   ],
   "source": [
    "# loading images\n",
    "dog_directory = Path(\"images\")\n",
    "\n",
    "breeds = []\n",
    "for breed in dog_directory.iterdir():\n",
    "    # count number of images in each breed\n",
    "    if breed.is_dir():\n",
    "        breed_count = len(list(breed.glob(\"*.jpg\")))\n",
    "        breeds.append((breed.name.split(\"-\", 1)[-1], breed_count))\n",
    "\n",
    "breeds.sort(key=lambda x: x[1], reverse=True)\n",
    "breeds = [breed[0] for breed in breeds[:10]]\n",
    "print(breeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4e07be31-32a6-4678-8de7-631b182c92ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 images for silky_terrier\n",
      "Loaded 140 images for Scottish_deerhound\n",
      "Loaded 140 images for Chesapeake_Bay_retriever\n",
      "Loaded 140 images for Ibizan_hound\n",
      "Loaded 140 images for wire-haired_fox_terrier\n",
      "Loaded 140 images for Saluki\n",
      "Loaded 140 images for cocker_spaniel\n",
      "Loaded 140 images for schipperke\n",
      "Loaded 140 images for borzoi\n",
      "Loaded 140 images for Pembroke\n",
      "Loaded 140 images for komondor\n",
      "Loaded 140 images for Staffordshire_bullterrier\n",
      "Loaded 140 images for standard_poodle\n",
      "Loaded 140 images for Eskimo_dog\n",
      "Loaded 140 images for English_foxhound\n",
      "Loaded 140 images for golden_retriever\n",
      "Loaded 140 images for Sealyham_terrier\n",
      "Loaded 140 images for Japanese_spaniel\n",
      "Loaded 140 images for .DS_Store\n",
      "Loaded 140 images for miniature_schnauzer\n",
      "Loaded 140 images for malamute\n",
      "Loaded 140 images for malinois\n",
      "Loaded 140 images for Pekinese\n",
      "Loaded 140 images for giant_schnauzer\n",
      "Loaded 140 images for Mexican_hairless\n",
      "Loaded 140 images for Doberman\n",
      "Loaded 140 images for standard_schnauzer\n",
      "Loaded 140 images for dhole\n",
      "Loaded 140 images for German_shepherd\n",
      "Loaded 140 images for Bouvier_des_Flandres\n",
      "Loaded 140 images for Siberian_husky\n",
      "Loaded 140 images for Norwich_terrier\n",
      "Loaded 140 images for Irish_terrier\n",
      "Loaded 140 images for Norfolk_terrier\n",
      "Loaded 140 images for Saint_Bernard\n",
      "Loaded 140 images for Border_terrier\n",
      "Loaded 140 images for briard\n",
      "Loaded 140 images for Tibetan_mastiff\n",
      "Loaded 140 images for bull_mastiff\n",
      "Loaded 280 images for Maltese_dog\n",
      "Loaded 280 images for Kerry_blue_terrier\n",
      "Loaded 280 images for kuvasz\n",
      "Loaded 280 images for Greater_Swiss_Mountain_dog\n",
      "Loaded 280 images for Lakeland_terrier\n",
      "Loaded 280 images for Blenheim_spaniel\n",
      "Loaded 280 images for basset\n",
      "Loaded 280 images for West_Highland_white_terrier\n",
      "Loaded 280 images for Chihuahua\n",
      "Loaded 280 images for Border_collie\n",
      "Loaded 280 images for redbone\n",
      "Loaded 420 images for Irish_wolfhound\n",
      "Loaded 420 images for bluetick\n",
      "Loaded 420 images for miniature_poodle\n",
      "Loaded 420 images for Cardigan\n",
      "Loaded 420 images for EntleBucher\n",
      "Loaded 420 images for Norwegian_elkhound\n",
      "Loaded 420 images for German_short-haired_pointer\n",
      "Loaded 560 images for Bernese_mountain_dog\n",
      "Loaded 560 images for papillon\n",
      "Loaded 560 images for Tibetan_terrier\n",
      "Loaded 560 images for Gordon_setter\n",
      "Loaded 560 images for American_Staffordshire_terrier\n",
      "Loaded 560 images for vizsla\n",
      "Loaded 560 images for kelpie\n",
      "Loaded 560 images for Weimaraner\n",
      "Loaded 560 images for miniature_pinscher\n",
      "Loaded 560 images for boxer\n",
      "Loaded 560 images for chow\n",
      "Loaded 560 images for Old_English_sheepdog\n",
      "Loaded 560 images for pug\n",
      "Loaded 560 images for Rhodesian_ridgeback\n",
      "Loaded 560 images for Scotch_terrier\n",
      "Loaded 700 images for Shih-Tzu\n",
      "Loaded 700 images for affenpinscher\n",
      "Loaded 700 images for whippet\n",
      "Loaded 700 images for Sussex_spaniel\n",
      "Loaded 700 images for otterhound\n",
      "Loaded 700 images for flat-coated_retriever\n",
      "Loaded 700 images for English_setter\n",
      "Loaded 700 images for Italian_greyhound\n",
      "Loaded 700 images for Labrador_retriever\n",
      "Loaded 700 images for collie\n",
      "Loaded 700 images for cairn\n",
      "Loaded 700 images for Rottweiler\n",
      "Loaded 700 images for Australian_terrier\n",
      "Loaded 700 images for toy_terrier\n",
      "Loaded 700 images for Shetland_sheepdog\n",
      "Loaded 700 images for African_hunting_dog\n",
      "Loaded 700 images for Newfoundland\n",
      "Loaded 700 images for Walker_hound\n",
      "Loaded 700 images for Lhasa\n",
      "Loaded 700 images for beagle\n",
      "Loaded 840 images for Samoyed\n",
      "Loaded 840 images for Great_Dane\n",
      "Loaded 840 images for Airedale\n",
      "Loaded 840 images for bloodhound\n",
      "Loaded 840 images for Irish_setter\n",
      "Loaded 840 images for keeshond\n",
      "Loaded 840 images for Dandie_Dinmont\n",
      "Loaded 840 images for basenji\n",
      "Loaded 840 images for Bedlington_terrier\n",
      "Loaded 840 images for Appenzeller\n",
      "Loaded 840 images for clumber\n",
      "Loaded 840 images for toy_poodle\n",
      "Loaded 980 images for Great_Pyrenees\n",
      "Loaded 980 images for English_springer\n",
      "Loaded 1120 images for Afghan_hound\n",
      "Loaded 1120 images for Brittany_spaniel\n",
      "Loaded 1120 images for Welsh_springer_spaniel\n",
      "Loaded 1120 images for Boston_bull\n",
      "Loaded 1120 images for dingo\n",
      "Loaded 1120 images for soft-coated_wheaten_terrier\n",
      "Loaded 1120 images for curly-coated_retriever\n",
      "Loaded 1120 images for French_bulldog\n",
      "Loaded 1120 images for Irish_water_spaniel\n",
      "Loaded 1260 images for Pomeranian\n",
      "Loaded 1260 images for Brabancon_griffon\n",
      "Loaded 1260 images for Yorkshire_terrier\n",
      "Loaded 1260 images for groenendael\n",
      "Loaded 1400 images for Leonberg\n",
      "Loaded 1400 images for black-and-tan_coonhound\n",
      "X=array([[[[0.92848178, 0.83427475, 0.79501483],\n",
      "         [0.94236061, 0.84565729, 0.8020088 ],\n",
      "         [0.85099294, 0.79275584, 0.72039548],\n",
      "         ...,\n",
      "         [0.93947145, 0.87050174, 0.86758416],\n",
      "         [0.91802428, 0.85498605, 0.84344159],\n",
      "         [0.88037278, 0.83130708, 0.76405693]],\n",
      "\n",
      "        [[0.85340094, 0.77971926, 0.74013784],\n",
      "         [0.8840888 , 0.79822402, 0.75724169],\n",
      "         [0.82823414, 0.76577956, 0.70477903],\n",
      "         ...,\n",
      "         [0.88609608, 0.81461212, 0.78716814],\n",
      "         [0.83917443, 0.76394841, 0.72849223],\n",
      "         [0.82055437, 0.74483861, 0.69011343]],\n",
      "\n",
      "        [[0.89331583, 0.86312476, 0.79703697],\n",
      "         [0.85375466, 0.80207093, 0.74563555],\n",
      "         [0.8555594 , 0.81095514, 0.74681855],\n",
      "         ...,\n",
      "         [0.72050073, 0.6587029 , 0.58123566],\n",
      "         [0.81018547, 0.74507168, 0.65065827],\n",
      "         [0.89615988, 0.83159812, 0.72145462]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.30774048, 0.3126625 , 0.33093744],\n",
      "         [0.33909948, 0.35474037, 0.44259411],\n",
      "         [0.64015976, 0.68004201, 0.8136851 ],\n",
      "         ...,\n",
      "         [0.3943784 , 0.39392247, 0.54260449],\n",
      "         [0.47665669, 0.48211655, 0.5914982 ],\n",
      "         [0.78152946, 0.84448565, 0.885719  ]],\n",
      "\n",
      "        [[0.38269331, 0.393483  , 0.39776999],\n",
      "         [0.40974569, 0.4305099 , 0.52426866],\n",
      "         [0.44666282, 0.49546249, 0.63581095],\n",
      "         ...,\n",
      "         [0.46175957, 0.46236555, 0.58344236],\n",
      "         [0.52645992, 0.53681658, 0.65417581],\n",
      "         [0.56024032, 0.62573742, 0.71492254]],\n",
      "\n",
      "        [[0.38911675, 0.37958103, 0.36826159],\n",
      "         [0.37325341, 0.40357461, 0.45825402],\n",
      "         [0.59146453, 0.65146483, 0.72468302],\n",
      "         ...,\n",
      "         [0.64036516, 0.64411178, 0.73211783],\n",
      "         [0.64766516, 0.66043631, 0.77992921],\n",
      "         [0.58001346, 0.64867269, 0.78072495]]],\n",
      "\n",
      "\n",
      "       [[[0.81014179, 0.89570348, 0.98972797],\n",
      "         [0.81665651, 0.89273655, 0.98728464],\n",
      "         [0.82914423, 0.89274148, 0.987389  ],\n",
      "         ...,\n",
      "         [0.92185658, 0.95991266, 0.99184671],\n",
      "         [0.91559409, 0.95538306, 0.98855962],\n",
      "         [0.91214271, 0.96091169, 0.99572335]],\n",
      "\n",
      "        [[0.82611902, 0.91170001, 0.99930957],\n",
      "         [0.83548593, 0.91395246, 0.99946778],\n",
      "         [0.83965554, 0.90781058, 0.999392  ],\n",
      "         ...,\n",
      "         [0.93625278, 0.9660132 , 0.98993011],\n",
      "         [0.93516023, 0.96447182, 0.98794941],\n",
      "         [0.9300876 , 0.95792558, 0.98050572]],\n",
      "\n",
      "        [[0.81302658, 0.89681786, 0.99304646],\n",
      "         [0.82430822, 0.90361493, 0.9993542 ],\n",
      "         [0.81891331, 0.89556454, 0.99998103],\n",
      "         ...,\n",
      "         [0.96758208, 0.98795344, 0.9984228 ],\n",
      "         [0.97351722, 0.99236154, 0.99888879],\n",
      "         [0.98563312, 0.99432178, 0.99851565]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.56670708, 0.52132253, 0.33239893],\n",
      "         [0.53548869, 0.49334586, 0.30851121],\n",
      "         [0.5232866 , 0.45669012, 0.32344198],\n",
      "         ...,\n",
      "         [0.27422717, 0.28500587, 0.16061918],\n",
      "         [0.26118288, 0.27482985, 0.15334121],\n",
      "         [0.3451267 , 0.34638814, 0.15300015]],\n",
      "\n",
      "        [[0.56181516, 0.51732829, 0.30449904],\n",
      "         [0.54279288, 0.51901127, 0.28061405],\n",
      "         [0.52203645, 0.44431022, 0.29761511],\n",
      "         ...,\n",
      "         [0.32248483, 0.29246213, 0.18659816],\n",
      "         [0.31127663, 0.30144828, 0.19189626],\n",
      "         [0.33468732, 0.32445548, 0.19264495]],\n",
      "\n",
      "        [[0.52251374, 0.47813103, 0.29857983],\n",
      "         [0.48166044, 0.4671287 , 0.24939411],\n",
      "         [0.54447396, 0.47479593, 0.32413249],\n",
      "         ...,\n",
      "         [0.37839597, 0.35479753, 0.23498241],\n",
      "         [0.3133689 , 0.30686414, 0.20657171],\n",
      "         [0.27860409, 0.26087159, 0.18663424]]],\n",
      "\n",
      "\n",
      "       [[[0.38237175, 0.38655561, 0.39970605],\n",
      "         [0.39379267, 0.39995576, 0.40066231],\n",
      "         [0.38080504, 0.38490149, 0.39601167],\n",
      "         ...,\n",
      "         [0.29011009, 0.35822436, 0.41163727],\n",
      "         [0.35206944, 0.3930705 , 0.41317225],\n",
      "         [0.62319663, 0.60587857, 0.56461408]],\n",
      "\n",
      "        [[0.38381455, 0.38777871, 0.40311018],\n",
      "         [0.39299215, 0.39735118, 0.40758882],\n",
      "         [0.38883496, 0.39341309, 0.40457776],\n",
      "         ...,\n",
      "         [0.27411464, 0.3418551 , 0.39418509],\n",
      "         [0.3738757 , 0.41636227, 0.42601363],\n",
      "         [0.68126559, 0.66654838, 0.61107874]],\n",
      "\n",
      "        [[0.37004798, 0.37886487, 0.40368719],\n",
      "         [0.37304059, 0.38716121, 0.40430179],\n",
      "         [0.3865548 , 0.41003071, 0.4317422 ],\n",
      "         ...,\n",
      "         [0.33122911, 0.37890719, 0.40659795],\n",
      "         [0.42163185, 0.43689565, 0.42542812],\n",
      "         [0.67830847, 0.66606962, 0.60526055]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.43770712, 0.40541255, 0.33140421],\n",
      "         [0.5246578 , 0.49151046, 0.40221712],\n",
      "         [0.31714051, 0.33184278, 0.24545599],\n",
      "         ...,\n",
      "         [0.01040516, 0.01397964, 0.02991145],\n",
      "         [0.00725673, 0.0108312 , 0.02676301],\n",
      "         [0.0056728 , 0.00924549, 0.0251773 ]],\n",
      "\n",
      "        [[0.43840744, 0.40345927, 0.31862686],\n",
      "         [0.47836173, 0.44852475, 0.37304598],\n",
      "         [0.35565317, 0.35377469, 0.28009881],\n",
      "         ...,\n",
      "         [0.00455499, 0.00473742, 0.01294568],\n",
      "         [0.00140058, 0.001583  , 0.00979126],\n",
      "         [0.00109498, 0.00127741, 0.00948567]],\n",
      "\n",
      "        [[0.35042097, 0.31978865, 0.2023817 ],\n",
      "         [0.47387361, 0.45453365, 0.33611396],\n",
      "         [0.42170739, 0.41495288, 0.29378088],\n",
      "         ...,\n",
      "         [0.00624494, 0.00624494, 0.01408808],\n",
      "         [0.00309061, 0.00309061, 0.01093375],\n",
      "         [0.00278538, 0.00278538, 0.01062852]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.08449578, 0.12527084, 0.07002691],\n",
      "         [0.06953812, 0.17866817, 0.09537461],\n",
      "         [0.06521439, 0.1668531 , 0.08909272],\n",
      "         ...,\n",
      "         [0.06748885, 0.21315624, 0.11099405],\n",
      "         [0.06949961, 0.21113534, 0.11135078],\n",
      "         [0.075612  , 0.17619097, 0.10377943]],\n",
      "\n",
      "        [[0.0956938 , 0.20984639, 0.12363959],\n",
      "         [0.05634847, 0.25089406, 0.13689659],\n",
      "         [0.05059915, 0.2418545 , 0.12877236],\n",
      "         ...,\n",
      "         [0.07101439, 0.29216542, 0.16226026],\n",
      "         [0.07748268, 0.28897921, 0.16317335],\n",
      "         [0.09750271, 0.22682256, 0.13876052]],\n",
      "\n",
      "        [[0.05105501, 0.22219304, 0.11510636],\n",
      "         [0.02083801, 0.28133649, 0.14451647],\n",
      "         [0.01312006, 0.27075238, 0.13441966],\n",
      "         ...,\n",
      "         [0.0548207 , 0.30297227, 0.1578594 ],\n",
      "         [0.0610946 , 0.29925253, 0.15789393],\n",
      "         [0.09391487, 0.24718804, 0.14246103]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.23481157, 0.3609579 , 0.08607581],\n",
      "         [0.22767287, 0.40259044, 0.0091375 ],\n",
      "         [0.29384492, 0.48926291, 0.03174334],\n",
      "         ...,\n",
      "         [0.3530436 , 0.55056841, 0.04328991],\n",
      "         [0.40252723, 0.59132272, 0.0790091 ],\n",
      "         [0.28610068, 0.42413336, 0.08885077]],\n",
      "\n",
      "        [[0.18991678, 0.31320303, 0.08179604],\n",
      "         [0.21459716, 0.37868042, 0.01748046],\n",
      "         [0.24951014, 0.43290272, 0.0397962 ],\n",
      "         ...,\n",
      "         [0.3493056 , 0.52428022, 0.04710134],\n",
      "         [0.38229344, 0.55287885, 0.07697244],\n",
      "         [0.30918168, 0.43535176, 0.14126896]],\n",
      "\n",
      "        [[0.17453509, 0.25446407, 0.09653951],\n",
      "         [0.20365242, 0.31175351, 0.07462017],\n",
      "         [0.2131115 , 0.33135475, 0.08942222],\n",
      "         ...,\n",
      "         [0.27976506, 0.40923572, 0.10860758],\n",
      "         [0.28007821, 0.4112725 , 0.1073352 ],\n",
      "         [0.23653751, 0.33811788, 0.12969611]]],\n",
      "\n",
      "\n",
      "       [[[0.76832634, 0.72471969, 0.81009052],\n",
      "         [0.70275427, 0.68225131, 0.72833877],\n",
      "         [0.34741136, 0.33471431, 0.37615716],\n",
      "         ...,\n",
      "         [0.68811142, 0.52897243, 0.44999261],\n",
      "         [0.68515601, 0.52601702, 0.4470372 ],\n",
      "         [0.68142063, 0.52228164, 0.44330181]],\n",
      "\n",
      "        [[0.7579232 , 0.72850043, 0.77370853],\n",
      "         [0.73294709, 0.7095325 , 0.79378276],\n",
      "         [0.55383293, 0.53009293, 0.63699151],\n",
      "         ...,\n",
      "         [0.69170533, 0.5425525 , 0.46016736],\n",
      "         [0.68861628, 0.53946346, 0.45707832],\n",
      "         [0.68551717, 0.53636434, 0.4539792 ]],\n",
      "\n",
      "        [[0.54612789, 0.52286521, 0.58403603],\n",
      "         [0.49424966, 0.47870784, 0.52867809],\n",
      "         [0.61274058, 0.59688516, 0.65627477],\n",
      "         ...,\n",
      "         [0.69023581, 0.54938186, 0.46355808],\n",
      "         [0.69219408, 0.55134012, 0.46551634],\n",
      "         [0.69368207, 0.55282811, 0.46700433]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.03300122, 0.03008693, 0.03434473],\n",
      "         [0.02754001, 0.02704394, 0.02092836],\n",
      "         [0.02825094, 0.02825055, 0.02040728],\n",
      "         ...,\n",
      "         [0.52351587, 0.41980525, 0.39104715],\n",
      "         [0.37430971, 0.29250314, 0.27477079],\n",
      "         [0.28419891, 0.21648412, 0.20427559]],\n",
      "\n",
      "        [[0.09725895, 0.0777738 , 0.0543264 ],\n",
      "         [0.04744264, 0.042966  , 0.03033386],\n",
      "         [0.03713828, 0.03712596, 0.02925906],\n",
      "         ...,\n",
      "         [0.64512638, 0.50594084, 0.4561253 ],\n",
      "         [0.61840572, 0.49377521, 0.45025026],\n",
      "         [0.58657719, 0.46973077, 0.42989079]],\n",
      "\n",
      "        [[0.15301923, 0.11609183, 0.05195418],\n",
      "         [0.10225862, 0.09251468, 0.06929044],\n",
      "         [0.0574074 , 0.05737021, 0.04947007],\n",
      "         ...,\n",
      "         [0.6493264 , 0.50781105, 0.44322109],\n",
      "         [0.63808019, 0.49688487, 0.42977781],\n",
      "         [0.64125888, 0.49953821, 0.43249175]]],\n",
      "\n",
      "\n",
      "       [[[0.26299593, 0.46816304, 0.00533565],\n",
      "         [0.25665967, 0.5088384 , 0.0331248 ],\n",
      "         [0.26375641, 0.52845589, 0.03255544],\n",
      "         ...,\n",
      "         [0.4616415 , 0.29742106, 0.02946522],\n",
      "         [0.48738365, 0.30670521, 0.03714758],\n",
      "         [0.52780551, 0.33993257, 0.05268699]],\n",
      "\n",
      "        [[0.25023798, 0.44031247, 0.00376143],\n",
      "         [0.22846671, 0.46486716, 0.01614911],\n",
      "         [0.21806485, 0.47119326, 0.00525832],\n",
      "         ...,\n",
      "         [0.44798573, 0.28783848, 0.01752279],\n",
      "         [0.48309394, 0.30565862, 0.03741483],\n",
      "         [0.54599489, 0.36143218, 0.07339172]],\n",
      "\n",
      "        [[0.23979479, 0.42583842, 0.01486879],\n",
      "         [0.21041855, 0.43157803, 0.01365787],\n",
      "         [0.2076907 , 0.44775353, 0.010163  ],\n",
      "         ...,\n",
      "         [0.47414966, 0.31900585, 0.04566445],\n",
      "         [0.49865368, 0.32984283, 0.06019343],\n",
      "         [0.53283653, 0.35992193, 0.07417198]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.41925346, 0.54822381, 0.0632901 ],\n",
      "         [0.28689167, 0.43065595, 0.01528895],\n",
      "         [0.32809128, 0.50652574, 0.06983784],\n",
      "         ...,\n",
      "         [0.33188297, 0.35965649, 0.09527463],\n",
      "         [0.32166355, 0.40092254, 0.07749393],\n",
      "         [0.3653876 , 0.43209964, 0.05092179]],\n",
      "\n",
      "        [[0.39539348, 0.50978685, 0.01307455],\n",
      "         [0.3786913 , 0.52859139, 0.0432349 ],\n",
      "         [0.41526966, 0.58180565, 0.09188752],\n",
      "         ...,\n",
      "         [0.2012324 , 0.2023932 , 0.0448192 ],\n",
      "         [0.2493939 , 0.28725669, 0.05501894],\n",
      "         [0.36694755, 0.4698455 , 0.09249173]],\n",
      "\n",
      "        [[0.38333797, 0.50871135, 0.00444571],\n",
      "         [0.36840864, 0.54581801, 0.02567393],\n",
      "         [0.45109664, 0.61498455, 0.09133967],\n",
      "         ...,\n",
      "         [0.34609621, 0.3538353 , 0.09472148],\n",
      "         [0.42806401, 0.46796789, 0.14316169],\n",
      "         [0.37067039, 0.52782923, 0.13031361]]]]), y=array([2, 2, 2, ..., 9, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "# load images\n",
    "X = []\n",
    "y = []\n",
    "width, height = 128, 128 # image resolution\n",
    "\n",
    "for breed in dog_directory.iterdir():\n",
    "    breed_name = breed.name.split(\"-\", 1)[-1]\n",
    "    for i, image_path in enumerate(breed.glob(\"*.jpg\")):\n",
    "        if breed_name not in breeds:\n",
    "            continue\n",
    "        image = plt.imread(image_path)\n",
    "        image = np.rot90(image, 90*(i+1)) # rotate image\n",
    "        image = resize(image, (width, height, 3))\n",
    "        X.append(image)\n",
    "        y.append(breeds.index(breed_name))\n",
    "        if i >= 139:  # do 140 images each\n",
    "            break\n",
    "    print(f\"Loaded {len(X)} images for {breed_name}\")\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"{X=}, {y=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b5e5ba3e-f34e-4ad0-bde2-b26a7e2748e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# label data\n",
    "labels = to_categorical(y, num_classes=10)\n",
    "labels = np.array(labels, dtype=\"int32\")\n",
    "print(labels)                                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02090b31",
   "metadata": {},
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6be11b9a-8745-46f6-83d4-c940b67966f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test samples\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, labels,   \n",
    "    test_size = 0.07, random_state=10, shuffle=True\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, \n",
    "    test_size = 0.07, random_state=10, shuffle=True\n",
    ")\n",
    "\n",
    "# Scale data\n",
    "X_train = X_train/255\n",
    "X_val = X_val/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1665b36e-9d73-4ccb-8505-01e8af61bd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:(1209, 128, 128, 3)\n",
      "y_train:(1209, 10)\n",
      "X_val: \t(92, 128, 128, 3)\n",
      "y_val: \t(92, 10)\n",
      "X_test: (99, 128, 128, 3)\n",
      "y_test: (99, 10)\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure everything is as expected\n",
    "print('X_train:' + str(X_train.shape))\n",
    "print('y_train:' + str(y_train.shape))\n",
    "print('X_val: \\t'  + str(X_val.shape))\n",
    "print('y_val: \\t'  + str(y_val.shape))\n",
    "print('X_test: '  + str(X_test.shape))\n",
    "print('y_test: '  + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe7515",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f099b7-2037-4697-ae3e-99040f215795",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: unmatched '[' (430631068.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[96], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"train_acc={np.mean(history.history[\"accuracy\"])}\")\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: unmatched '['\n"
     ]
    }
   ],
   "source": [
    "def train_model(activation=\"sigmoid\", stride=(4, 4), epoch=100):\n",
    "    model = Sequential([\n",
    "    layers.Input(shape=(height, width, 3)),\n",
    "    layers.Conv2D(256, 3, padding=\"same\", activation=activation),\n",
    "    layers.MaxPooling2D(strides=stride), # default: stride=(2,2)\n",
    "    layers.Conv2D(512, 3, padding=\"same\", activation=activation),\n",
    "    layers.MaxPooling2D(strides=stride),\n",
    "    layers.Conv2D(724, 3, padding=\"same\", activation=activation),\n",
    "    # layers.MaxPooling2D(strides=stride),\n",
    "    # layers.Conv2D(128, 3, padding=\"same\", activation=activation),\n",
    "    # layers.MaxPooling2D(strides=stride),\n",
    "    # layers.Conv2D(256, 3, padding=\"same\", activation=activation),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation=activation),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    history = model.fit(X_train, y_train, epochs = epoch, validation_data=(X_val, y_val))\n",
    "    model.evaluate(X_val, y_val)\n",
    "    return history, model\n",
    "\n",
    "def class_report(history, model):\n",
    "    print(f\"train_acc={np.mean(history.history[\"accuracy\"])}\")\n",
    "    print(f\"val_acc={np.mean(history.history[\"val_accuracy\"])}\")\n",
    "    res = model.predict(X_test)\n",
    "    y_test = np.array(y_test, dtype=\"int32\")\n",
    "\n",
    "    p, q = [], []\n",
    "\n",
    "    for i in range(len(res)):\n",
    "        p.append(np.argmax(res[i]))\n",
    "        pred = breeds[np.argmax(res[i])]\n",
    "        q.append(np.argmax(y_test[i]))\n",
    "\n",
    "        actual = breeds[np.argmax(y_test[i])]\n",
    "        # print(f\"Predicted: {pred}, Actual: {actual}\")\n",
    "\n",
    "    # top_breeds = [\"French_bulldog\", \"golden_retriever\", \n",
    "    # \"German_shepherd\", \"standard_poodle\", \"Samoyed\", \n",
    "    # \"French_bulldog\", \"beagle\", \"Rottweiler\"]\n",
    "    print(classification_report(p, q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e5a873",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40820af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid (control)\n",
    "history, model = train_model()\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Error vs Epochs (Sigmoid Activation Function)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "class_report(history, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da41d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden Layers\n",
    "# 5 Layers\n",
    "history, model = train_model()\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Error vs Epochs (Five Hidden Layers)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "class_report(history, model)\n",
    "\n",
    "# 3 Layers\n",
    "history, model = train_model()\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Error vs Epochs (Three Hidden Layers)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "class_report(history, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad689c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Functions\n",
    "# ReLU\n",
    "history, model = train_model(\"leaky_relu\")\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Error vs Epochs (Leaky ReLU Activation Function)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "class_report(history, model)\n",
    "\n",
    "# Tanh\n",
    "history, model = train_model(\"tanh\")\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Error vs Epochs (Tanh Activation Function)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "class_report(history, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d1903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterations\n",
    "# 400 Iterations\n",
    "history, model = train_model(\"sigmoid\", (4, 4), 200)\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Error vs Epochs (400 Iterations)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "class_report(history, model)\n",
    "\n",
    "# 200 Iterations\n",
    "history, model = train_model(\"sigmoid\", (4, 4), 100)\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Error vs Epochs (200 Iterations)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "class_report(history, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84883233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strides\n",
    "# (3, 3))\n",
    "history, model= train_model(\"sigmoid\", (3, 3), 100)\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Error vs Epochs (3x3 Strides)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "class_report(history, model)\n",
    "\n",
    "# (4, 4)\n",
    "history, model = train_model(\"sigmoid\", (4, 4), 100)\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Error vs Epochs (4x4 Strides)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "class_report(history, model)\n",
    "\n",
    "# (5, 5)\n",
    "history, model = train_model(\"sigmoid\", (5, 5), 100)\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Error vs Epochs (5x5 Strides)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "class_report(history, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c8e3eb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.0832 - loss: 8.0036 - precision_31: 0.0725 - recall_31: 0.0414 - val_accuracy: 0.0761 - val_loss: 2.7753 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.1010 - loss: 2.4246 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0543 - val_loss: 2.3868 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 3/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.0857 - loss: 2.3465 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3103 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 4/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.0678 - loss: 2.3510 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1304 - val_loss: 2.3223 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 5/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.0908 - loss: 2.3368 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0761 - val_loss: 2.3646 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 6/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.0897 - loss: 2.3699 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0543 - val_loss: 2.3478 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 7/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.0900 - loss: 2.3365 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1087 - val_loss: 2.3297 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 8/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.0767 - loss: 2.3426 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1087 - val_loss: 2.3513 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.1103 - loss: 2.3545 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3388 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 10/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 0.0980 - loss: 2.3538 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1304 - val_loss: 2.3089 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 11/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.0938 - loss: 2.3457 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1304 - val_loss: 2.3613 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 12/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.1015 - loss: 2.3781 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0543 - val_loss: 2.3309 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 13/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.1137 - loss: 2.3477 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3486 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 14/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.0879 - loss: 2.3688 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1304 - val_loss: 2.4383 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 15/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.0899 - loss: 2.3701 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1304 - val_loss: 2.3186 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 16/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.1144 - loss: 2.3652 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.2960 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 17/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1s/step - accuracy: 0.1038 - loss: 2.3386 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0543 - val_loss: 2.3407 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 18/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1s/step - accuracy: 0.1084 - loss: 2.3318 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1087 - val_loss: 2.3680 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 19/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.1148 - loss: 2.3603 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1087 - val_loss: 2.3608 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 20/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.0986 - loss: 2.3439 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3708 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 21/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.1098 - loss: 2.3925 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0543 - val_loss: 2.3463 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 22/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.1054 - loss: 2.3541 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1304 - val_loss: 2.3083 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 23/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.0978 - loss: 2.3495 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0543 - val_loss: 2.3720 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 24/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - accuracy: 0.0838 - loss: 2.3352 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1087 - val_loss: 2.4068 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 25/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.1086 - loss: 2.3586 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.4198 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 26/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.1008 - loss: 2.3743 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0761 - val_loss: 2.3603 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 27/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.0991 - loss: 2.3603 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0543 - val_loss: 2.4253 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 28/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.1066 - loss: 2.3437 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3293 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 29/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.0908 - loss: 2.3632 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3217 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 30/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.0978 - loss: 2.3350 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0543 - val_loss: 2.4623 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 31/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - accuracy: 0.1018 - loss: 2.3726 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1087 - val_loss: 2.3762 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 32/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - accuracy: 0.0865 - loss: 2.3685 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0543 - val_loss: 2.3943 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 33/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.0976 - loss: 2.3656 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0543 - val_loss: 2.3913 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 34/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.1064 - loss: 2.3743 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0761 - val_loss: 2.3571 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 35/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.1153 - loss: 2.3589 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3471 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 36/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.0922 - loss: 2.3592 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1087 - val_loss: 2.3360 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 37/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.0941 - loss: 2.3449 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3382 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 38/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.0953 - loss: 2.3724 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0761 - val_loss: 2.4560 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 39/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.0965 - loss: 2.3848 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3517 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 40/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.1179 - loss: 2.3448 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0543 - val_loss: 2.3603 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 41/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.1197 - loss: 2.3490 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3939 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 42/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.0875 - loss: 2.3516 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3280 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 43/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.0905 - loss: 2.3558 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3398 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 44/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.0788 - loss: 2.3581 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3035 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 45/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.0961 - loss: 2.3415 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3540 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 46/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.0887 - loss: 2.3791 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0761 - val_loss: 2.3992 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 47/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.0915 - loss: 2.3734 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1304 - val_loss: 2.2971 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 48/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.1015 - loss: 2.3520 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1304 - val_loss: 2.3550 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 49/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.1066 - loss: 2.3613 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3303 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 50/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.0932 - loss: 2.3397 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1304 - val_loss: 2.2957 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 51/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.1156 - loss: 2.3525 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0761 - val_loss: 2.3660 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 52/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.1155 - loss: 2.3446 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0543 - val_loss: 2.4045 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 53/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 2s/step - accuracy: 0.1090 - loss: 2.3613 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0761 - val_loss: 2.3715 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 54/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.1232 - loss: 2.3293 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.4051 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 55/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.0938 - loss: 2.3778 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0761 - val_loss: 2.3706 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 56/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 2s/step - accuracy: 0.1310 - loss: 2.3340 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3380 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 57/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.0906 - loss: 2.3772 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3448 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 58/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.1214 - loss: 2.3443 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.2969 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 59/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 2s/step - accuracy: 0.0916 - loss: 2.3444 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0870 - val_loss: 2.3486 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 60/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - accuracy: 0.1088 - loss: 2.3442 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0870 - val_loss: 2.4520 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 61/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.0952 - loss: 2.3997 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1087 - val_loss: 2.3167 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 62/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - accuracy: 0.0878 - loss: 2.3600 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0761 - val_loss: 2.3305 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 63/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 2s/step - accuracy: 0.0807 - loss: 2.3493 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0761 - val_loss: 2.5003 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 64/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.1099 - loss: 2.3777 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0761 - val_loss: 2.3497 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 65/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.0728 - loss: 2.3616 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0543 - val_loss: 2.3456 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 66/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.1015 - loss: 2.3316 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0870 - val_loss: 2.3213 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 67/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.0948 - loss: 2.3469 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0761 - val_loss: 2.3492 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 68/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.0990 - loss: 2.3557 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1304 - val_loss: 2.3331 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 69/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.1030 - loss: 2.3644 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3794 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 70/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 2s/step - accuracy: 0.0963 - loss: 2.3498 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0543 - val_loss: 2.3504 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 71/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.0897 - loss: 2.3700 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.1196 - val_loss: 2.3891 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 72/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 2s/step - accuracy: 0.1015 - loss: 2.3637 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00 - val_accuracy: 0.0870 - val_loss: 2.3534 - val_precision_31: 0.0000e+00 - val_recall_31: 0.0000e+00\n",
      "Epoch 73/100\n",
      "\u001b[1m27/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.1143 - loss: 2.3317 - precision_31: 0.0000e+00 - recall_31: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "# Rotate image\n",
    "history, model = train_model(\"sigmoid\", (5, 5), 100)\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Error vs Epochs (Rotating Image)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "class_report(history, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "78523b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalized\n",
    "# history, model = train_model(\"sigmoid\", 100)\n",
    "# plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "# plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "# plt.legend(loc=\"upper right\")\n",
    "# plt.title(\"Error vs Epochs (Normalization)\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# class_report(history, model)\n",
    "\n",
    "# # Not Normalized\n",
    "# history, model = train_model(\"sigmoid\", 100)\n",
    "# plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "# plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "# plt.legend(loc=\"upper right\")\n",
    "# plt.title(\"Error vs Epochs (No Normalization)\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# class_report(history, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ddbd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularizers\n",
    "def train_model_reg(l, activation=\"sigmoid\", stride=(4,4), epoch=100):\n",
    "    model = Sequential([\n",
    "    layers.Input(shape=(height, width, 3)),\n",
    "    layers.Conv2D(256, 3, padding=\"same\", activation=activation, kernel_regularizer=regularizers.l2(l)),\n",
    "    layers.MaxPooling2D(strides=stride), # default: stride=(2,2)\n",
    "    layers.Conv2D(512, 3, padding=\"same\", activation=activation, kernel_regularizer=regularizers.l2(l)),\n",
    "    layers.MaxPooling2D(strides=stride),\n",
    "    layers.Conv2D(724, 3, padding=\"same\", activation=activation, kernel_regularizer=regularizers.l2(l)),\n",
    "    # layers.MaxPooling2D(strides=stride),\n",
    "    # layers.Conv2D(128, 3, padding=\"same\", activation=activation),\n",
    "    # layers.MaxPooling2D(strides=stride),\n",
    "    # layers.Conv2D(256, 3, padding=\"same\", activation=activation),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation=activation, kernel_regularizer=regularizers.l2(l)),\n",
    "    layers.Dense(10, activation=\"softmax\", kernel_regularizer=regularizers.l2(l))\n",
    "    ])\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    history = model.fit(X_train, y_train, epochs = epoch, validation_data=(X_val, y_val))\n",
    "    model.evaluate(X_val, y_val)\n",
    "    return history\n",
    "\n",
    "# Lambda = 0.0001\n",
    "history, model = history = train_model(0.0001)\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Error vs Epochs (Lambda = 0.0001)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "class_report(history, model)\n",
    "\n",
    "# Lambda = 0.001\n",
    "history, model = train_model(0.001)\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Error vs Epochs (Lambda = 0.001)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "class_report(history, model)\n",
    "\n",
    "# Lambda = 0.01\n",
    "history, model = train_model(0.01)\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Error vs Epochs (Lambda = 0.01)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "class_report(history, model)\n",
    "\n",
    "# Lambda = 1.0\n",
    "history, model = train_model(1.0)\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Error vs Epochs (Lambda = 1.0)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "class_report(history, model)\n",
    "\n",
    "# Lambda = 10.0\n",
    "history, model = train_model(10.0)\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Error vs Epochs (Lambda = 10.0)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "class_report(history, model)\n",
    "\n",
    "# Lambda = 100.0\n",
    "history, model = train_model(100.0)\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Error\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Error vs Epochs (Lambda = 100.0)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "class_report(history, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
